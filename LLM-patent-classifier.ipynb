{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bc02a8",
   "metadata": {},
   "source": [
    "## 0. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pandas scikit-learn tqdm python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ceffe4",
   "metadata": {},
   "source": [
    "## 1. 基本配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#数据路径配置\n",
    "BASE_DIR = Path(\"xxx\")\n",
    "TRAIN_CSV = BASE_DIR / \"train_data.csv\"\n",
    "TEST_CSV  = BASE_DIR / \"test_data.csv\"\n",
    "\n",
    "DATASET_NAME = TRAIN_CSV.stem\n",
    "PER_FOLD_PREFIX         = BASE_DIR / f\"{DATASET_NAME}_cv_fold_preds\"\n",
    "CV_PER_FOLD_METRICS_CSV = BASE_DIR / f\"{DATASET_NAME}_cv_metrics_per_fold.csv\"\n",
    "CV_SUMMARY_CSV          = BASE_DIR / f\"{DATASET_NAME}_cv_summary.csv\"\n",
    "\n",
    "#选择具体LLMs\n",
    "\"\"\"\n",
    "QWEN_API_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\"\n",
    "QWEN_MODEL   = \"qwen-plus-latest\"\n",
    "QWEN_API_KEY = os.getenv(\"QWEN_API_KEY\", \"xxx\")\n",
    "\n",
    "or\n",
    "\n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/chat/completions\"\n",
    "DEEPSEEK_MODEL   = \"deepseek-reasoner\"\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\", \"xxx\")\n",
    "\"\"\"\n",
    "\n",
    "RANDOM_STATE = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc831271",
   "metadata": {},
   "source": [
    "## 2. 读取数据与清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV, encoding=\"utf-8-sig\")\n",
    "\n",
    "need = {\"orig_index\", \"abs\", \"label\"}\n",
    "missing = need - set(train_df.columns)\n",
    "assert not missing, f\"CSV 缺少列: {missing}\"\n",
    "\n",
    "train_df = train_df.copy()\n",
    "train_df[\"abs\"] = train_df[\"abs\"].astype(str).str.strip()\n",
    "train_df = train_df.dropna(subset=[\"abs\"])\n",
    "train_df[\"label\"] = pd.to_numeric(train_df[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "train_df[\"label\"] = train_df[\"label\"].clip(0, 1)\n",
    "\n",
    "print(\"Loaded rows:\", len(train_df))\n",
    "print(\"Label distribution:\", train_df[\"label\"].value_counts().to_dict())\n",
    "print(train_df.head(3)[[\"orig_index\", \"label\", \"abs\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bafd0",
   "metadata": {},
   "source": [
    "## 3. 基于 ChineseBERT 的相似样例检索\n",
    "（在基于Few-Shot Promting的策略中寻找相似判例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "MODEL_NAME = \"shannonai/ChineseBERT-base\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def encode_texts(texts, batch_size=32, max_length=512):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        \n",
    "        encoded_input = tokenizer(\n",
    "            batch_texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=max_length, \n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "            sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "            sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "            \n",
    "        all_embeddings.append(sentence_embeddings.cpu().numpy())\n",
    "        \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "def make_fold_encoder_and_index(train_texts, train_labels, batch_size=32):\n",
    "    X_train_vec = encode_texts(train_texts, batch_size=batch_size)\n",
    "    train_df_fold = pd.DataFrame({\"abs\": train_texts, \"label\": train_labels})\n",
    "    pos_mask = train_df_fold[\"label\"] == 1\n",
    "    neg_mask = train_df_fold[\"label\"] == 0\n",
    "    X_pos = X_train_vec[pos_mask.values] if pos_mask.sum() > 0 else None\n",
    "    X_neg = X_train_vec[neg_mask.values] if neg_mask.sum() > 0 else None\n",
    "    \n",
    "    pos_rows = train_df_fold[pos_mask].reset_index(drop=True) if pos_mask.sum() > 0 else pd.DataFrame(columns=[\"abs\", \"label\"])\n",
    "    neg_rows = train_df_fold[neg_mask].reset_index(drop=True) if neg_mask.sum() > 0 else pd.DataFrame(columns=[\"abs\", \"label\"])\n",
    "\n",
    "    return encode_texts, X_train_vec, X_pos, X_neg, pos_rows, neg_rows\n",
    "\n",
    "def topk_from_block_local(q_vec, X_block, rows, k, redundancy_threshold=0.90):\n",
    "    if (X_block is None) or (getattr(X_block, \"shape\", (0,0))[0] == 0) or k <= 0:\n",
    "        return []\n",
    "    \n",
    "    if q_vec.ndim == 1:\n",
    "        q_vec = q_vec.reshape(1, -1)\n",
    "    # 1. 计算 Query 与所有候选样本的余弦相似度\n",
    "    sims = cosine_similarity(q_vec, X_block).ravel()\n",
    "    # 2. 按相似度从大到小排序，获取索引\n",
    "    sorted_idx = sims.argsort()[::-1]\n",
    "    selected_indices = []\n",
    "    # 3. 贪婪策略遍历候选样本，加入去冗余判断\n",
    "    for idx in sorted_idx:\n",
    "        if not selected_indices:\n",
    "            # 第一条最相似的总是直接加入\n",
    "            selected_indices.append(idx)\n",
    "        else:\n",
    "            # 获取当前候选样本的向量\n",
    "            candidate_vec = X_block[idx].reshape(1, -1)\n",
    "            # 获取已经选入集合的样本向量矩阵\n",
    "            selected_vecs = X_block[selected_indices]\n",
    "            # 计算当前候选样本与【已选入样本】之间的相似度\n",
    "            intra_sims = cosine_similarity(candidate_vec, selected_vecs).ravel()\n",
    "            # 如果当前样本与已选样本库中任何一条的相似度都低于阈值，说明具备足够的多样性\n",
    "            if np.max(intra_sims) < redundancy_threshold:\n",
    "                selected_indices.append(idx) \n",
    "        # 满足 K 条数量要求即停止检索\n",
    "        if len(selected_indices) >= k:\n",
    "            break\n",
    "            \n",
    "    return rows.iloc[selected_indices][[\"abs\", \"label\"]].to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6804e",
   "metadata": {},
   "source": [
    "## 4. 提示工程设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对AI技术及专利进行基础定义\n",
    "AI_DEFINITION_CORE = \"\"\"凡技术属于以下三条路径之一，即视为 AI 相关：\n",
    "1. 机器人学（Robotics）：具备感知–决策–执行闭环的自主/半自主系统与其核心算法与系统（如SLAM、路径规划、运动控制、协同控制、机器人感知与融合、机器人操作策略、类人/移动/工业/服务/医疗机器人等）。\n",
    "2. 学习系统（Learning Systems）：以机器学习/深度学习/强化学习等为核心方法的技术与任务（如监督/无监督/自监督/生成式模型、卷积/循环/Transformer、表示学习、图学习、概率生成模型、SVM/Boosting/随机森林等；AI专用硬件若核心目的在于训练/推理加速亦归此类）。\n",
    "3. 符号系统（Symbolic Systems）：基于符号/逻辑推理与知识表示的AI（如专家系统、知识库/本体、规则引擎+推理机、规划/搜索、约束满足问题CSP、自动定理证明等）。\n",
    "\n",
    "请注意，这次任务并非是一次“关键词检索”，很多专利的摘要中并不会直接体现上述关键词或者相关联的词汇，但是你需要根据语义推理出其内涵，从而对其进行判断。\n",
    "判定应关注技术实质是否以以上方法为核心创新，或者设计而非只在背景介绍中泛泛提及。\"\"\"\n",
    "\n",
    "def _sanitize(text: str, max_len=1500) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    s = str(text)\n",
    "    s = s.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = s.replace('\"', '\\\\\"')\n",
    "    s = s.strip()[:max_len]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f911b16",
   "metadata": {},
   "source": [
    "### 4.1. Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf59596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_zero_shot(abstract):\n",
    "    abs_text = _sanitize(abstract, max_len=1500)\n",
    "    \n",
    "    prompt_content = f\"\"\"请阅读下方给出的中文专利摘要，并判断它是否属于“AI相关专利”。在本任务中，请严格依据以下定义与判断标准：\n",
    "【AI相关专利定义】\n",
    "{AI_DEFINITION_CORE}\n",
    "\n",
    "请只输出一个数字：\n",
    "1：属于AI相关专利；\n",
    "0：不属于AI相关专利。\n",
    "不要输出任何解释或其他文字。\n",
    "\n",
    "以下是需要判断的专利摘要：\n",
    "【待判断专利摘要】\n",
    "{abs_text}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_content}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d40fe",
   "metadata": {},
   "source": [
    "### 4.2. Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33edd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_few_shot(abstract, shots):\n",
    "    example_lines = []\n",
    "    for i, ex in enumerate(shots):\n",
    "        label = int(ex[\"label\"])\n",
    "        label_text = \"正类（标签 = 1）\" if label == 1 else \"负类（标签 = 0）\"\n",
    "        ex_abs = _sanitize(ex[\"abs\"], max_len=220)\n",
    "        example_lines.append(f\"【示例{i+1}：{label_text}】\\n摘要内容：{ex_abs}\\n\")\n",
    "        \n",
    "    examples_block = \"\\n\".join(example_lines)\n",
    "    abs_text = _sanitize(abstract, max_len=1500)\n",
    "\n",
    "    prompt_content = f\"\"\"你将阅读下方给出的中文专利摘要，并判断它们是否属于“AI相关专利”。请首先理解以下定义与判断标准：\n",
    "【AI相关专利定义】\n",
    "{AI_DEFINITION_CORE}\n",
    "\n",
    "请学习以下样例，该样例展示了专利的摘要以及对应其是否属于AI相关专利：\n",
    "{examples_block}\n",
    "现在，请在理解上述定义与示例的基础上，对下方“待判断摘要”进行分类。请只输出一个数字：\n",
    "1：属于AI相关专利；\n",
    "0：不属于AI相关专利。\n",
    "不要输出任何其他内容。\n",
    "\n",
    "以下是需要判断的专利摘要：\n",
    "【待判断专利摘要】\n",
    "{abs_text}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_content}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e2dd4",
   "metadata": {},
   "source": [
    "### 4.3. Role-Based Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_role_based(abstract):\n",
    "    abs_text = _sanitize(abstract, max_len=1500)\n",
    "    \n",
    "    system_role = \"你现在的身份是一名长期从事技术情报分析的专利审查员，负责筛选“AI相关专利”。\"\n",
    "    \n",
    "    user_content = f\"\"\"请你根据以下定义与判断标准，阅读下方的中文专利摘要，并给出是否属于“AI相关专利”的判断。AI相关专利的定义与判断标准如下：\n",
    "【AI相关专利的定义】\n",
    "{AI_DEFINITION_CORE}\n",
    "\n",
    "请站在“专利分析员”的立场上，先根据上述标准完成判断，但在最终输出中只给出一个数字：\n",
    "1：属于AI相关专利；\n",
    "0：不属于AI相关专利。\n",
    "不要输出任何解释或附加文字。\n",
    "\n",
    "以下是需要判断的专利摘要：\n",
    "【待判断专利摘要】\n",
    "{abs_text}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3953fa6",
   "metadata": {},
   "source": [
    "## 5. API封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbd13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, random, requests\n",
    "\n",
    "#根据具体LLMs进行调整\n",
    "def call_deepseek(messages, model=DEEPSEEK_MODEL, temperature=0.0, max_retries=5, timeout=60):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    }\n",
    "    backoff = 1.5\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=timeout)\n",
    "            if resp.status_code == 200:\n",
    "                data = resp.json()\n",
    "                content = None\n",
    "                try:\n",
    "                    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        content = data[\"choices\"][0][\"text\"]\n",
    "                    except Exception:\n",
    "                        content = json.dumps(data)\n",
    "\n",
    "                start = content.find(\"{\")\n",
    "                end   = content.rfind(\"}\")\n",
    "                if start != -1 and end != -1 and end > start:\n",
    "                    content_json = content[start:end+1]\n",
    "                else:\n",
    "                    content_json = content\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(content_json)\n",
    "                except Exception:\n",
    "                    return {\"label\": 0}\n",
    "                lbl = obj.get(\"label\", None)\n",
    "                try:\n",
    "                    lbl = int(lbl)\n",
    "                    lbl = 1 if lbl == 1 else 0\n",
    "                except Exception:\n",
    "                    lbl = 0\n",
    "                return {\"label\": lbl}\n",
    "            else:\n",
    "                time.sleep((backoff ** attempt) + random.random())\n",
    "        except Exception:\n",
    "            time.sleep((backoff ** attempt) + random.random())\n",
    "    return {\"label\": 0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1bf39",
   "metadata": {},
   "source": [
    "## 6. 对测试集逐条判读并保存预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 策略配置，可选: \"zero_shot\", \"few_shot\", \"role_based\"\n",
    "PROMPT_STRATEGY = \"role_based\"\n",
    "# 投票次数设置\n",
    "VOTE_N = 3\n",
    "# Few-Shot Prompting中TOP-K判例数设置\n",
    "K_PER_CLASS = 3\n",
    "OUTPUT_DIR = BASE_DIR\n",
    "OUTPUT_FILE = OUTPUT_DIR / f\"test_preds_{PROMPT_STRATEGY}.csv\"\n",
    "\n",
    "print(\"正在加载数据集...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_data = pd.read_csv(TEST_CSV)\n",
    "\n",
    "X_train = train_df[\"abs\"].fillna(\"\").astype(str).tolist()\n",
    "y_train = train_df[\"label\"].astype(int).tolist()\n",
    "\n",
    "X_test = test_data[\"abs\"].fillna(\"\").astype(str).tolist()\n",
    "if \"label\" in test_data.columns:\n",
    "    y_test = test_data[\"label\"].astype(int).tolist()\n",
    "else:\n",
    "    raise ValueError(\"ERROR：测试集中未找到 'label' 列！请检查测试集文件是否包含真实的标签数据。\")\n",
    "\n",
    "def parse_numeric_label(response_text, default=0):\n",
    "    text = str(response_text).strip()\n",
    "    match = re.search(r'\\d', text)\n",
    "    if match:\n",
    "        val = int(match.group())\n",
    "        return val if val in [0, 1] else default\n",
    "    return default\n",
    "\n",
    "if PROMPT_STRATEGY == \"few_shot\":\n",
    "    print(\"正在构建全量训练集的 ChineseBERT 检索库，请稍候...\")\n",
    "    encoder, X_train_vec, X_pos, X_neg, pos_rows, neg_rows = make_fold_encoder_and_index(X_train, y_train)\n",
    "\n",
    "    def pick_few_shots_local(abstract, k_per_class=K_PER_CLASS):\n",
    "        q = encoder(abstract) \n",
    "        exs = []\n",
    "        if X_pos is not None:\n",
    "            exs += topk_from_block_local(q, X_pos, pos_rows, k_per_class)\n",
    "        if X_neg is not None:\n",
    "            exs += topk_from_block_local(q, X_neg, neg_rows, k_per_class)\n",
    "        return exs\n",
    "\n",
    "preds = []\n",
    "\n",
    "for txt in tqdm(X_test, desc=f\"Testing on test_data ({PROMPT_STRATEGY})\"):\n",
    "    gate = None\n",
    "    if \"heuristic_gate\" in globals():\n",
    "        try:\n",
    "            gate = heuristic_gate(txt)\n",
    "        except Exception:\n",
    "            gate = None\n",
    "\n",
    "    if gate is not None:\n",
    "        preds.append(int(gate))\n",
    "        continue\n",
    "\n",
    "    if PROMPT_STRATEGY == \"few_shot\":\n",
    "        shots = pick_few_shots_local(txt, K_PER_CLASS)\n",
    "        messages = make_prompt_few_shot(txt, shots)\n",
    "    elif PROMPT_STRATEGY == \"zero_shot\":\n",
    "        messages = make_prompt_zero_shot(txt)\n",
    "    elif PROMPT_STRATEGY == \"role_based\":\n",
    "        messages = make_prompt_role_based(txt)\n",
    "    else:\n",
    "        raise ValueError(f\"未知的策略类型: {PROMPT_STRATEGY}\")\n",
    "\n",
    "    if VOTE_N == 1:\n",
    "        out = call_deepseek(messages, temperature=0.0)\n",
    "        label = parse_numeric_label(out)\n",
    "    else:\n",
    "        votes = []\n",
    "        for _ in range(VOTE_N):\n",
    "            out = call_deepseek(messages, temperature=0.3)\n",
    "            votes.append(parse_numeric_label(out))\n",
    "        label = 1 if sum(votes) > (VOTE_N / 2) else 0\n",
    "\n",
    "    preds.append(label)\n",
    "\n",
    "\n",
    "preds = np.array(preds, dtype=int)\n",
    "test_df_out = pd.DataFrame({\n",
    "    \"abs\": X_test,\n",
    "    \"true_label\": y_test,\n",
    "    \"pred_label\": preds\n",
    "})\n",
    "\n",
    "test_df_out.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n 测试集预测完成！\")\n",
    "print(f\"当前策略: [{PROMPT_STRATEGY}]\")\n",
    "print(f\"结果已保存至: {OUTPUT_FILE} (共 {len(X_test)} 条数据)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4833b31",
   "metadata": {},
   "source": [
    "## 7. 计算并导出指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "OUTPUT_FILE = BASE_DIR / f\"test_preds_{PROMPT_STRATEGY}.csv\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_FILE):\n",
    "    raise FileNotFoundError(f\"未找到预测文件：{OUTPUT_FILE}\\n请先运行前面的推理代码。\")\n",
    "\n",
    "print(\"找到的预测文件：\")\n",
    "print(\" -\", OUTPUT_FILE)\n",
    "\n",
    "df = pd.read_csv(OUTPUT_FILE, encoding=\"utf-8-sig\")\n",
    "assert {\"true_label\",\"pred_label\"}.issubset(df.columns), f\"{OUTPUT_FILE} 缺少 true_label 或 pred_label 列\"\n",
    "\n",
    "y_true = df[\"true_label\"].astype(int).values\n",
    "y_pred = df[\"pred_label\"].astype(int).values\n",
    "\n",
    "TP = int(((y_true==1) & (y_pred==1)).sum())\n",
    "FN = int(((y_true==1) & (y_pred==0)).sum())\n",
    "FP = int(((y_true==0) & (y_pred==1)).sum())\n",
    "TN = int(((y_true==0) & (y_pred==0)).sum())\n",
    "\n",
    "acc = float(accuracy_score(y_true, y_pred))\n",
    "prec = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "rec = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "f1  = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "\n",
    "metrics_data = [{\n",
    "    \"Strategy\": PROMPT_STRATEGY,\n",
    "    \"TP\": TP, \"FN\": FN, \"FP\": FP, \"TN\": TN,\n",
    "    \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1,\n",
    "    \"n_val\": int(len(y_true))\n",
    "}]\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_out = BASE_DIR / f\"test_metrics_{PROMPT_STRATEGY}.csv\"\n",
    "metrics_df.to_csv(metrics_out, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nMetrics saved to:\", metrics_out)\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(metrics_df)\n",
    "except ImportError:\n",
    "    print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
